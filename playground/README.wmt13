Jednojazycna data
-----------------

* Google Ngrams
  /net/data/google-czech-ngrams-2009/
  Navod, jak z nich vyrobit LM:
    http://www-speech.sri.com/projects/srilm/manpages/srilm-faq.7.html

* CNK
  /mnt/ATLAS/data/CNK-SYN
  ...je treba zjistit, jak se lisi od toho, co jsem parsoval zde:
     /net/data/tectomt-SYN-WEB

* Webovy korpus 2011 (CWC2011, Johanka)
  /net/cluster/TMP/pecina/CWC2011
  nebo taky /mnt/ATLAS/data/CWC2011

                            sents   toks
    articles_shuffled       38 M    628 M
    blogs_shuffled          98 M    1249 M
    discussions_shuffled    82 M    1407 M
    TOTAL                   218 M   3284 M

  Konverzni skript:
    /home/bojar/diplomka/bin/vertical2factors --input-sent-regex='^<s>'

* WMT Mono News 20*
  /a/merkur3/TMP/tamchyna/wmt13/data
  Mixture-LM podle let? Ano, ale michat podle neceho aktualnejsiho nez wmt08.

* monitoring-tisk 2012
  /ha/seznamdata/texty_z_monitoringu
  nebo taky /mnt/ATLAS/data/MonitoringTisku1998-2012 (tam se to jeste vali)

* CzEng 1.0
  /net/data/czeng10-public-release
  Mixture-LM podle domen? Ano, urcite.
  Pozor, to michani bychom taky meli delat nejak lepe, mixovat na wmt08 se v
  roce 13 uz nemusi uplne hodit...

* Seznam.cz 2008
  /mnt/ATLAS/data/Seznam2008 (tam se to jeste vali)
  aktualne to lezi i zde:
  /ha/seznamdata/seznam_texty_z_webu/ftp/b-[0-9]*.gz
  ...pridaval bych to az jako posledni zdroj.
  ...zacal jsem pro ten ucel psat dva skripty, ale nepamatuji si, jak daleko jsem dosel:
    ufal-smt-playground/playground/augmented_corpora/prep-wmt10/
      select_czech_sents_from_seznamdata.pl
      refine_and_truecase_czech_sents.pl

* Martin Majlis -- webovy korpus
  ufal/~majlis/w2c

Dalsi?

Paralelni data
--------------

* CzEng 1.0
  /net/data/czeng10-public-release

* Prekladove pameti Evropskeho centra pro prevenci chorob
    http://langtech.jrc.ec.europa.eu/ECDC-TM.html

*? Neco stahnout pomoci Panacea Tools?

Dalsi?



Cisteni, normalizace
--------------------

Potrebujeme jednotnou pipeline. Kterou pouzit?

- TrTok na segmentaci na vety, nikoli na tokenizaci
- playground/treex_scenarios/{cs,en}Nm.scen
  ... Nm znaci normalizovane a na m-rovine.
  ... normalizace jsou prave bloky jako W2W::NormalizeCzechSentence
      jeste bychom normalizaci mohli zkontrolovat a vylepsit

* Kontrola jednotnosti

- doporucuju 64bit binarku suspicious_tokenization (pozor, nacita bigramy do pameti!):

  cat corpus1 corpus2 corpus3 | ~/tools/src/obotools/suspicious_tokenization \
  | numsort n3

  Vypise to neco jako:

se na           sena            24      1
na to           nato            18      2
do konce        dokonce         9       30
že na           žena            8       9
za to           zato            6       3
jako by         jakoby          5       1
z ní            zní             5       5
před tím        předtím         4       10

Zde je evidentni, ze jsou to vsechno plane poplachy. Ale mohou tam byt veci
jako "us." vs. "us .". Cisla za temi dvema variantami jsou pocty vyskytu jedne
a druhe varianty.


2013-03-05

- experimentuju s ruznym poctem referencnich vet
  - vetsi devset nepomohl
  - vic referenci by melo pomoct
  - posteditovane reference?
    - dve varianty za sebou?
    - dve varianty jako alternativni reference?
  - spojeni obycejnych + posteditovanych?
  ... vse celkem bez hmatatelnych rozdilu

  ... takto se to vyhodnocuje:
./qj devset-hpe-7sys 10.63.0.53 10.62.0.53 10.61.0.54 10.60.0.54 10.47.0.53 10.53.0.51 10.42.0.52 | sed 's/\*\*/2/;s/\*/1/' | tabrecalc 'EVAL COL1*COL2 LAVE\tCOL3' | grp --keys=2 --items=SUM1 | numsort 2

dosavadni vysledky:
sys1, 10.63.0.53        7
sys3, 10.61.0.54        10
sys5, 10.47.0.53        11
sys6, 10.53.0.51        11
sys2, 10.62.0.53        12
sys4, 10.60.0.54        12
sys7, 10.42.0.52        14

nejlepsi 10.42.0.52 je prekvapive DEVwmt11-hpe1:wmt11-hpe2, druhy je DEVnewstest2011:wmt11-extraref1:wmt11-extraref2:wmt11-extraref3 a DEVnewstest2011:wmt11-extraref1

- vyrobim korpus jen z titulku z monitoringu tisku
  pak vysekame titulky ze vsech devtestu a vyladime na tom vlastni preklad
    (bud obecneho mosese nebo navic s tim titulkovym lm)
  a pak prelozime testset dvakrat: normalne a titulkove
  ...a prislusne vety vezmeme z prislusnych casti


Odlisna spojeni:
- have to be careful not to get under an avalanche
potrebuje frazi "not to get" = "abyste se nedostali/la/lo"
...chtelo by to overit, jak se na takovehle pripady diva alignment...

- "obviously, " to naopak pekne preklada jako "je zrejme, ze"

- "believed in his motto saying that" = "rikajici", "ktere rika"
  (prvni volba je atypicky slovni tvar, druha volba zas generuje slovo navic a tim je mozna znevyhodnena"

Chyby:
- pojmenovane entity!
SRC     `` Charles University has been greatly involved in the festival . ''
REF     „ univerzita Karlova má na festivalu velký podíl . “
        „ Charles univerzity se významně podílely na festivalu “ .
        „ Charles univerzity se významně podílely na festivalu . “
        „ aktivit se významně podílely na festivalu “ . 
        „ aktivit se významně podílely na festivalu . “


2013-03-06

zkousim to filtrovani nbl: s.mert.b46a12c6.20130306-1737



2013-03-13
s.evaluator.ad31eb1e.20130313-0059  ... prvni vetsi tm, ale jen baseline lm
84747a50.20130313-1535 15.33±0.59 vetsi TM, vetsi LM, ale pomotane T1


2013-03-13

s.evaluator.249f2e54.20130313-2210  minibaseline T1
s.evaluator.3f5e6eef.20130313-2347  bug: LM na form-or-tag, model na tag
  -> oprava: s.evaluator.86ca92e0.20130314-1433
s.evaluator.1b6fda72.20130313-2353  stc->stc+stcORpossuf2F1k
  az bude, tak exploduj suf1, suf3, suf4, suf5, cng, tag, 200, 2k, 3k
  a z toho jsou odvozeniny suf2F1k a suf2F2k
  +stcOtagF500 je o drobecicek lepsi nez +tag v t0-0a1!



TODO:
- _NUM classes
- vetsi/lepsi devset pro vetsi data
- zjednoznacnit anglicke 'to understand' jako to-aby; a not-to-sign
  ... nikdo to neumi poznat, jedine to je z valence ridiciho slova
  ... co treba proste predikce z form|lemma|tag pro nasledujici TO uhodnout,
  ma-li (rucni) funktor AIM?
  Takto vysypu PCEDT: treex Write::Factored outcols=csA flags=escape_space:join_spaced_numbers -- /net/data/pcedt2.0/data/00/wsj_0001.treex.gz
   ... viz ./pcedt/
- zjednoznacnit anglicke ing?
  ... earthquake came to Calif. >killing< more than 50k people -> prislo a zabilo


2013-03-15

porozovani ohledne ttable-limit: limit 1000 pomohl jen o 0.02:
./hilidiff 249f2e54.20130313-2210 456db641.20130314-1649
...chtelo by to proverit multimertem

2013-03-19

s.evaluator.9d18288a.20130320-0034 je t0a1-0a1 s velkymi LM, ale chybi tam
news-taglm a dalsi; taky paralelni data nejsou maximalni, jen czeng

s.evaluator.6310dd23.20130320-0035 je t0-0a1, zase velke LM, ale chybi veci
jako vyse


zkousim take stcOtagF500 na velkych datech (t0-0a1): s.evaluator.5865fe2e.20130320-0048

a pak zkousim zvetsit paralelni data:
default: s.evaluator.b1742407.20130319-2346
1000phrases s200: s.evaluator.a1745cc4.20130319-1432




2013-03-21

continued to slide	nadale klesaly
contract to make ...	smlouvu na vyrobu ...



2013-03-21

k postupu 4ae63906.20130314-1532 11.94±0.53 vyrabim i variantu, ktera bude mit alignment na lematech: s.evaluator.8c55840d.20130321-1052 (11.70) ... cili horsi!



2013-03-21

Pro Pavla Pecinu:
s.evaluator.5cd35965.20130321-1100  ... odvozeno od 4ae63906.20130314-1532 11.94±0.53
  bude to sypat peclemma+pectag01


DOSUD NEJLEPSI:
6310dd23.20130320-0035 16.21±0.57
  ...odvozuju jeste 7gramy slov: s.evaluator.f21120f5.20130321-1117
  ...ne, tohle uz nepujde, musel bych rucne vypinat kndiscount vsude mozne

  ZKousim tedy udelat vsehcno roky v sedmigramech najednou: s.lm.10686e3c.20130321-1722
  A take cely czeng najednou: s.lm.27136953.20130321-1724

  A take zkousim 10gr na tagach: s.lm.1f637dbb.20130417-0016


osy:
- pocet jader v mgize: (maji i dalsi dva behy)
s.evaluator.84747a50.20130313-1535	1 jadro 	15.33±0.59 15.32±0.58 15.48±0.58	ali trval 113:59:38 (410378 s)
s.evaluator.9eae61de.20130321-1706	12 jader	15.44±0.57 15.52±0.57 15.26±0.58	ali trval 51:23:53 (185033 s)
s.evaluator.4dd6ba39.20130321-1708	giza    	15.48±0.58 15.56±0.59 15.54±0.58	ali trval 71:11:49 (256309 s)

giza	s.evaluator.1c099ee7.20130322-0016,s.evaluator.006482eb.20130322-0016,s.evaluator.0486f26e.20130322-0017
1jadro	s.evaluator.84747a50.20130313-1535,s.evaluator.1f6f117d.20130322-0016,s.evaluator.1c099ee7.20130322-0016
12jader	s.evaluator.9eae61de.20130321-1706,s.evaluator.2286434b.20130322-0015,s.evaluator.184e9c42.20130322-0015

giza vs. 1 jadro: s.multeval.357b2313.20130322-1548

giza vs. 12 jader: s.multeval.9c971272.20130322-1549

1 jadro vs. 12 jader: s.multeval.ea362f94.20130322-1550

Interpretace:
giza vs. 1 jadro:
n=3            BLEU (s_sel/s_opt/p)   METEOR (s_sel/s_opt/p) TER (s_sel/s_opt/p)    Length (s_sel/s_opt/p) 
baseline       15.5 (0.3/0.0/-)       21.1 (0.2/0.0/-)       66.9 (0.3/0.1/-)       98.0 (0.3/0.2/-)       
system 1       15.4 (0.3/0.1/0.00)    21.0 (0.2/0.0/0.02)    67.0 (0.3/0.1/0.03)    97.9 (0.3/0.1/0.14)    
...giza dava o 0.1 lepsi BLEU, METEOR i TER
... a je pst 0.00 (p-value), ze by se pozorovany rozdil mohl objevit jen pri nahodnem mertu



  
- alignment lemma/stem:
  s.evaluator.6310dd23.20130320-0035 (DONE)
  s.evaluator.dc354509.20130321-1613 (RUNNING)

- heldout pro lm:
  s.evaluator.6310dd23.20130320-0035 (DONE)
  s.evaluator.5c4d7991.20130322-0025 (RUNNING)
  s.evaluator.0fbdb860.20130322-1526 (RUNNING)
  s.evaluator.ff7e1412.20130322-1353 (RUNNING)

Reorderingy (jen czeng10):
tag-tag pro 9d18288a.20130320-0034 (15.73): s.rm.5e144dfa.20130321-1852 (RUNNING) a asi stejny s.rm.cb891802.20130321-1841 (DONE) 
  ... zkousim s.rm.cb891802.20130321-1841 (DONE) v s.evaluator.b225c1b0.20130328-1441 (OUTDATED) pro 15.73 => 16.14±0.56
stc-tag pro 6310dd23.20130320-0035 (16.21): s.rm.3d85d18e.20130414-2351
  ... vadny jsem zkousel v s.evaluator.b9f8cde6.20130402-2223 pro 16.21
  ... zkousim pro 37.66 v s.evaluator.45c0542c.20130414-2356
stc-stc univerzalni: s.rm.0fb000ee.20130321-1851 (DONE)
  ... zkousim v s.evaluator.60c74b1e.20130326-2159 (DONE) pro 16.21 => 15.93±0.57
  ... zkousim v s.evaluator.3bf8fe83.20130328-1451 (DONE) pro 15.73 => 15.87±0.57
  ... zkousim v s.evaluator.dcb164b9.20130414-2349 pro s.evaluator.81dce4a5.20130413-1543 (37.66) =>

Velke LM:
mono-ctk-all/csNmT1+form+lemma+tag	s.corpus.a7c9f3d5.20130321-1509
mono-tisk-all/csNmT1+form+lemma+tag	s.corpus.b36e3420.20130321-1511

sedmigramovy LM: (misto sestigramu)
s.lm.10686e3c.20130321-1722 (DONE 3.8G), lm sam je 2.7
zkusim ho prorezat a pak pouzit
s.prunelm.66ef5c8f.20130415-0003 (14)
- v 16.38 (5e3ba7d8.20130404-0902) =>  s.evaluator.c70c72e4.20130415-0031 !! lepsi: 16.42

Velky align: s.align.7daa5e91.20130321-1945

t0-0a1 s mmi: s.evaluator.0afd542a.20130324-1758
s.evaluator.d0716f30.20130323-0742
s.evaluator.4639b655.20130326-1143

2013-03-22

prunelm: (zatim jen prvni ze tri)
s.prunelm.dd6a8605.20130322-1439 (OUTDATED)
s.prunelm.2d4c0571.20130322-1442 (OUTDATED)
s.prunelm.cd915a7d.20130322-1453 (DONE)

Nahrady mixlm:
orig                          	                              14	                              16
s.mixlm.032fd94d.20130314-1548	s.prunelm.cd915a7d.20130322-1453	s.prunelm.0d0f1f93.20130324-2209
s.mixlm.17acb910.20130313-1013	s.prunelm.20cc4acc.20130324-2212	
s.mixlm.5946c8e8.20130313-1010	s.prunelm.ac2e42c9.20130324-2213	

stcOtagF500: s.mixlm.7d806f57.20130322-1629	s.prunelm.63dee741.20130326-2312
... otestuju 16.12±0.57 (4cff86bb.20130324-1410) ve variante s prunelm: s.evaluator.37b7f7bf.20130326-2318

varianta s prunelm 12: s.evaluator.89de7dc0.20130326-1001 -> 16.06±0.58 (mert 51 hodin, maxvmem 15g, asi spis ucpany cluster)
varianta s prunelm 14: s.evaluator.f05fa2f6.20130324-2229 -> 16.12±0.56 (mert 10 hodin, maxvmem 16g)
varianta s prunelm 16: s.evaluator.ccd12273.20130326-0957 -> 16.00±0.56 (mert47 hodin, maxvmem 18g)


Kriticka pozorovnani:
- musim se vejit do 30g, jinak to pobezi tragicky pomalu
  ... tak ne uplne, on to spis ucpal David Marecek...
- musim pridat taglm na mononews
  ... ale jak tak velky natrenujeme? asi bude nutno pouzit stupidbackoff nebo
      nizsi ngramy :-/

- zkusim vyrobit velky 10gr tagLM: s.mixlm.2f79af42.20130326-2339
  ... ten by pak patril do kdeceho, zejmena (po pruningu) do f9a1252f.20130322-1622 16.28±0.58
  ... mel jsem jen spatne zadani
  ... jenze ona i nahrada ma problemy: s.mixlm.ef7752b1.20130415-0041
      prerekvizity jsou nejake spatne


2013-03-26

rucne opravuju s.mixlm.2d9a21b0.20130326-1504 spoustim v qsubmitu
...hmm, tak to s pozadavkem na 80g zdechlo hned?
===> vyhodnoceno v s.evaluator.c2a1518b.20130329-2233   => 0.1623


2013-04-03

pro Pavla pecinu devtest jako indomain a out of domain:
zdroj: s.evaluator.f9a1252f.20130322-1622 => 0.1628
  delka frazi: s.evaluator.e9d6fa8f.20130404-0109 => 1.8987
o: s.evaluator.5b1efd7b.20130403-1308 => 0.1619
   k tomu varianta, ktera spocte i delku frazi:
     s.evaluator.7abeea5f.20130404-1012 => 2.0085
i: s.evaluator.c2bdc9e5.20130403-1309 => 0.1588
   k tomu varianta s delkou frazi: s.evaluator.85077e1b.20130404-0103 => 1.6631

    	                                  	BLEU  	Delka frazi
base	s.evaluator.f9a1252f.20130322-1622	0.1628	     1.8987
o   	s.evaluator.5b1efd7b.20130403-1308	0.1619	     2.0085
i   	s.evaluator.c2bdc9e5.20130403-1309	0.1588	     1.6631


zkusim delku frazi:
  s.evaluator.fee83a50.20130403-1421  ... prislusny translate jede s -T (s.translate.2185e4e0.20130403-1421)
  16.28±0.58  ma prumernou delku fraze 1.8987
  0.1614 s.evaluator.7bd26138.20130403-2206 pro nejlepsi t0a1-0a1 => 1.7771


A jeste pro ten pokus, ktery Ceslavovi nahodou vysel lepe:

Ceslav:
--- EXPERIMENT: d2e572c7.20130326-1047
--- BLEU        0.1633  [0.1580,0.1693]
--- PER         0.4831  [0.4775,0.4886]
--- TER         0.3322  [0.3262,0.3387]
--- CDER        0.3673  [0.3621,0.3723]
===> nahradou bude s.evaluator.5d7ab623.20130403-1856 s vypoctenymi delkami
===> s.translate.810d346d.20130403-1856 rika 1.7424
+++ EXPERIMENT: f05fa2f6.20130324-2229
+++ BLEU        0.1612  [0.1557,0.1669]
+++ PER         0.4821  [0.4766,0.4878]
+++ TER         0.3327  [0.3267,0.3389]
+++ CDER        0.3658  [0.3607,0.3705]
===> nahradou bude s.evaluator.1baf91ce.20130403-1856
===> s.translate.e28a8d45.20130403-1856/details.summary rika: 1.9577

Zajimave, takze zde naopak kratsi fraze v BLEU pomohly.

2013-04-03

zkusim taky pridat tectopreklad roku 2012 od Petry:
s.tm.605f08d6.20130402-1537
do b1742407.20130319-2346 15.95±0.58 (ktery je t0-0 s defaultnim ttablelimitem)
==> s.evaluator.a0802c94.20130403-2234 => 0.1573


2013-04-03

zkusim take maximalne zvetsit paralelni data, pridat europarl
cili po vzoru 23167e07.20130320-2358 15.97±0.57 udelat i f9a1252f.20130322-1622 16.28±0.58
=> s.evaluator.5e3ba7d8.20130404-0902 => 0.1638



2013-04-04

zkusim *omezit* delku fraze na 5 slov, protoze opakovane vidim, ze lepsi BLEU
  je tam, kde je nizsi prumerna delka fraze
Pro 16.33 s.evaluator.d2e572c7.20130326-1047 (prum. delka fraze 1.7424)
to zkousim zde:
s.evaluator.bc9ed080.20130404-1312 => 0.1599 (prum. delka fraze 1.9876)


Take zkusim ruzne limity cube pruningu:
Odvozeno z 16.33 (5d7ab623.20130403-1856)
s.evaluator.cc80a73f.20130404-1321	-s 10000 -cbp 2000 -cbd 10 => 0.1590
s.evaluator.4c163dd9.20130404-1322	-s 10000 -cbp 2000 -cbd 20 => 0.1606
s.evaluator.60f410dc.20130404-1725	-s 10000 -cbp 2000 -cbd 0 => 0.1617
s.evaluator.943d853a.20130405-0949	-s 10000 -cbp 3000 -cbd 0 => 0.1590
s.evaluator.f74bfedf.20130405-0950	-s 10000 -cbp 4000 -cbd 0 => 0.1597


2013-04-04
rucne postedituju a sbiram tipy:

- odlisit as=jako a as=neboť
- odlišit to-Verb na aby-X, infinitiv
- DWL!!!
- selected to play -> když jej vybrali, aby hrál
- invites taking advantage -> vyzývá k využití výhody
- is ending => je končí ... JAK SE TOHLE MUZE STAT? asi falesny bigram
  zajmeno+sloveso
- the authors appear to place the independence... se prelozilo jako 'autori, zda se, ze nezavislost'
- if you use them up => pokud je pouzivaji; nebo dokonce 'obratite-li se jim'
  ... tohle by mohl resit lokalni klasifikator
- what was going to happen to her marriage => co se delo/stane, aby se jeji manzelstvi
- more than lost points , the home trainer was sorry for high sick rate in the back => to je hodne nefrazove


2013-04-05
zhrubovani anglictiny:

tohle je ze souboru lex.0-0.f2e pro en->cs preklad, kdyz jsem jej utridil podle abecedy.

osvědčení ARC 0.1000000
osvědčení ATTESTATION 0.5555556
osvědčení Bigorre 0.2500000
osvědčení CAAP 0.0357143
osvědčení CCR 0.0757576
osvědčení CCRS 0.2500000
osvědčení CERTIFICATE 0.5833333
osvědčení CERTIFICATES 0.6078431
osvědčení CERTIFICATION 0.4545455
osvědčení CPC 0.0204866
osvědčení CPCS 0.0370370
osvědčení Certificate 0.2332016
osvědčení Certificates 0.3795380
osvědčení Certification 0.0620690
osvědčení Certifications 0.2272727
osvědčení Certifying 0.0434783

Kdybych tedy vzal vsechna slova, ktera maji udaj > 0.5 a nahradil je primo ceskym ekvivalentem mozna to pomuze alignmentu a hlavne pak prekladu

Vypada to celkem prijatelne, ale porad to neni dost vytezene:

nejrychlejší    Fastest 0.7500000
nejrychlejší    speediest       0.6310680

nejvyšší        highest 0.5148218
nejvyšší        nejvyšší        0.9375000
nejvyšší        tallest 0.5305344
největší        Largest 0.5909091
největší        Největší        0.7857143
největší        biggest 0.5325670
největší        největší        0.9186047

Ted z toho delam opravdu mapping:

zcat /net/tmp/bojar/wmt13-bojar/playground/4bfc76ec-lex-e2c-stc.gz | tr ' ' '\t' | coltest '$3 > 0.5 && $3 < 1.0  && $1 =~ /[[:alpha:]]/ ' | remove_singleton_lines 1 | sed 's/^/cls:/' | recut 2,1,3 | gzip > tools/map_tokens.maps/enstc-to-cscls50.gz

zkousim prvni variantu: rovnou ma na cilove strane tagy.
Je tam ale evidentni problem s pojmenovanymi entitami: tluce se to, zahazuju rozdil mezi Today a today...
baseline: 4ae63906.20130314-1532 11.94±0.53
se zhrubovanim: s.evaluator.e8828d33.20130410-0959  0.1187

Taky se podivej na historii prikazu v adresari:
/a/merkur3/TMP/bojar/wmt13-bojar/playground/wmt-baselines/s.tm.4bfc76ec.20130313-1327/model

2013-04-10

Srovnani s lonskem: na wmt12 jsme meli 16.10


ZKousim obri pokus 5e3ba7d8.20130404-0902 spustit taky opacne: trenovat na 2012, abych mohl evaluovat na 2011-posteditacich
-> s.evaluator.13bf06f4.20130412-2352 0.1824

Rovnou spoustim i vyhodnoceni toho behu na hpe1:
  s.evaluator.81dce4a5.20130413-1543 => vyslo neuveritelnych 0.3766

Ted do toho s.evaluator.81dce4a5.20130413-1543
zkusim pridat CzEngTMT: s.tm.0e31d8ab.20130315-2158
-> s.evaluator.9534457d.20130413-2225

Nasel jsem si, jaka nejvetsi data ma Petra prelozena od TectoMT

s.align.0b5ff00e.20130330-0226  mononews2009  ... tohle taky vypada OK (15mil.s.)
s.align.43e881c3.20130330-0147	mononews2008  ... tohle vypada v nahledu OK

zkusim tedy ten ladeny 12-11hpe predelat, aby pouzit jako paralelni data jen
mononews2009tmt
-> s.evaluator.160f1a1d.20130419-0939



A pak do toho pokusu zkusim pripojit Tectodata od Petry: (jeji pokus byl 13.73)
- jde o tuto frazovou tabulku: s.tm.605f08d6.20130402-1537, ale jak koukam
  alignment tam spustila na formach, coz neni uplne stastne, kdyby aspon
  lcstem4...




2013-04-14

navrh zjemnovani anglictiny pomoci ceskych cilovych lemat

krok transaug
  CORPUS=c-news
  SRCAUG=enNmT1+stc
  ALISTEP=...
  TGTAUG=csNmT1+lemma
  OUTFACTS=cslemma
  TRANSFLAGS="--"

divoky prikaz, ktery pripravi ten faktor pochazejici z druhe reci
V kroku tm:

ziplines --delim corpus/corpus.src.gz <(ziplines --item-d='\t' corpus/corpus.tgt.gz corpus/corpus.src.gz <(../../scripts/reverse_alignment.pl alignment.custom) | ../tools/move_info_along_ali.pl ) | tr ' ' '\t' | blockwise transpose | tt | less

Zkousel jsem ho zde: s.tm.3439d5e4.20130404-0901/.history-bojar



A ted ho zobecnim, pricemz info se bude tahat z tgt do src:
CORP=czeng10+europarl
SRCAUG=enNmT1+stc
TGTAUG=csNmT1+lemma
ALILABEL=enNmT1-lemma-csNmT1-lemma
ALIORREVALI=ali
ALISYM=gdfa
a pak:
ziplines --delim <(./corpman -dump $CORP/$SRCAUG) <(ziplines --item-d='\t' <(./corpman -dump $CORP/$TGTAUG) <(./corpman -dump $CORP/$SRCAUG) <(./corpman -dump $CORP/$ALISYM-$ALILABEL+$ALIORREVALI | ../scripts/reverse_alignment.pl ) | tools/move_info_along_ali.pl ) | tr ' ' '\t' | blockwise transpose | tt | less



2013-04-16

podle Philippovy rady zkousim u 16.42 zmensit max-phrase-length:
na 5: s.evaluator.5862c133.20130416-0046 -> 0.1636
na 4: s.evaluator.bb59e9bf.20130416-0055 -> 0.1631
na 6: s.evaluator.54f6a944.20130416-0056 -> 0.1647
na 7: s.evaluator.aecb8ce9.20130417-0001 -> 0.1645
na 8: s.evaluator.a6636099.20130417-0011 -> 0.1629
**** Pomohlo nepatrne, kdyz jsem pouzil jen fraze do delky 6.
To by ale taky mohlo naznacovat, ze spravna delka fraze je takova, ktera
odpovida ngramu LM.

Zkusim z nejlepsiho pokusu 16.47 (s.evaluator.54f6a944.20130416-0056) naschval
*vyhodit* LM z paralelnich dat:
s.evaluator.f4b02947.20130417-0028 -> 0.1646
Rucne na to kouknu, jestli to opravdu vychazi nastejno.

HLOUPE CHYBY:
- s.evaluator.f4b02947.20130417-0028: Hasek ' s successor -> Hasek je nastupce
- Austria 's pavillion: Rakousko je pavilonu
- the US credit unions -> za USA , družstevní záložny
...cili na zdrojove strane bych potreboval zduraznit, ze neco je privlastovaci
...POS model t0a1-t0a1 je kapku lepsi, ale stejne mnoho jmen nezvlada
   (Goodlattes', Moreno's, lawsuit's)
- was asked by a customer -> byl požádán , aby zákazník
- the ADB ' s forecast of 7.5 per cent economic
  => the Bad prognóza 7 , 5 procent



2013-04-17

analyza rozdilu:

1. seber anonymni tracebacky:

mkdir -p anonymous-tracebacks
qsubmit 'for f in `eman sel t evaluator d`; do eman tb --anon --vars --ign=corpus $f > anonymous-tracebacks/$f; done' --jobname=anonymous-tracebacks

2. udelej z nich diffy:

mkdir -p anonymous-diffs
qsubmit 'for a in anonymous-tracebacks/*; do for b in anonymous-tracebacks/*; do diff $a $b > anonymous-diffs/$(basename $a)-$(basename $b); done; done' -jobname=anonymous-diffs

3. seber v md5sumy, velikosti diffu, skore:

cd anonymous-diffs
md5sum s.evaluator.* > md5sums

ls -l | grep s.eva > sizes
  # rucne uprav na velikost\tsoubor

# seber seznam experimentu:
cut -f2 sizes | cut -d- -f1,2 | uniq > exps

# seber jejich skore:
cat exps | suffix /scores | prefix ../ | lcat -fl=- | grep BLE | cut -f 1,3 | sed 's|\.\./||;s|/scores||' > scores

4. zkompletuj udaje do jednoho souboru:
  recut 1,2,2 md5sums | paste - <(cut -f2 md5sums | sed 's/-s/       s/') | coltest '$4 ne $5' | map scores --mapcol=4,5 | map sizes --src=2 --tgt=1 --mapc=3 | tabrecalc "COL1-\tEVAL COL5 -COL4 LAVE" > all

5. Ve vimu ho takto zpracovavej shlukni:

:%!grp --keys=1 --items=ALL,2,COLLECT3,AVG4,AVG6,6,COLLECT2 --prec=4 2>/dev/null | numsort 4 | sed 's/, / /g'

ve vypisu je:
- hash diffu
- kolik diffu ma stejny hash
- jakou ma ten diff velikost v bytech
- jake je prumerne pocatecni BLEU (cili jak dobry experiment to vylepsuje)
- jake je prumerne zlepseni
- kolik ruznych zlepseni bylo dosazeno (pokud jen 1, znamena to, ze jde spis o
  replikovany experiment, pokud mnoho, tak je to celkem provereno)
- seznam vsech diffu, z nich by stacil vlastne jeden...

A takto se pak divam, v cem ten diff spocival:
(stisknu F1 na diffu, ktery mne zajima)

:map <F1> V:!(cut -f8 \| cut -d' ' -f1 \| xargs cat ; echo ----------------------------------------)\| write bojar pts/12<CR>u

Co jsou uzitecne rozdily, tj. checklist, co nezapomenout:

- europarl v paralelnich datech?
- nezvysovat limit cbp
- cdb mit nastavene na 0
- nezmensovat max-phrase-length
- neladit na hpe
- ladit na 2 referencich radsi nez dlouhem devsetu
- ovsem je lepsi ladit na *konkatenaci* obyc+hpe nez konkatenaci mnoha obyc
  s.evaluator.6b1ab349.20130222-1204-s.evaluator.ed379474.20130305-2317
- je lepsi ladit na wmt11+hpe1 nez na hpe1:hpe2
  s.evaluator.0a0f57cb.20130305-1722-s.evaluator.ed379474.20130305-2317
  A totez potvrzeno i bez zmeny MIRA/MERT:
  s.evaluator.0a0f57cb.20130305-1722-s.evaluator.e1ec6500.20130305-1716
- zdrojove tagy preklad kazi: t0a1-0a1 je horsi nez t0-0a1
  s.evaluator.49bc89b5.20130314-1317-s.evaluator.66f26076.20130312-2300


Jaky devset:
baseline 04556990.20130307-1347 10.66±0.53
dve reference: c1e52f36.20130305-1718 0.1062
... cili podle bleu je nejlepsi ladit jen na wmt11



2013-04-17

zkousim zjistit, jak vselijak se preklada 'to', abych to pak zkusil hadat jen z anglictiny a tim zlepsil preklad:

ziplines --delim <(./corpman -dump $CORP/$SRCAUG) <(ziplines --item-d='\t' <(./corpman -dump $CORP/$TGTAUG) <(./corpman -dump $CORP/$SRCAUG) <(./corpman -dump $CORP/$ALISYM-$ALILABEL+$ALIORREVALI | ../scripts/reverse_alignment.pl ) | tools/move_info_along_ali.pl ) | tr ' ' '\t' | blockwise transpose | tt | grep '^to ' | head -n 20000 | see > clip-20k-translations-of-to

Dalo by se tomu rikat tgt-side-tagging (nebo tagging by the target)


2013-04-17

Velke zapomenute modely prorezu:

s.prunelm.6e612092.20130417-1959 (DONE)   	cwc-articles	6
s.prunelm.1b34d02b.20130417-2021 (DONE)   	cwc-articles	7
s.prunelm.6e396383.20130417-2000 (DONE)   	cwc-blogs   	6
s.prunelm.3ebbe0bb.20130417-2015 (FAILED)	cwc-blogs   	7
s.prunelm.0e2319de.20130419-1402 (DONE)	cnk-news    	7
  ... rucne opravuju s.lm.9921e4a8.20130417-2004
s.prunelm.7ce3231b.20130417-2006 (DONE)   	cnk-other   	7

s.prunelm.aa9f1cfa.20130417-2155 (OUTDATED)	cwc-articles	10 tag
  oprava: s.klm.eeea10ba.20130421-0051
  a na ni navazuje s.prunelm.4aef063a.20130421-0053
s.prunelm.e9c2e609.20130417-2200 (FAILED)	cnk-news	10 tag
  ... rucne opravuju s.lm.f83ea0e1.20130417-2155
  ... radsi predelavam pomoci klm:
      s.klm.b0e2b8ad.20130421-0046
      ...a na to navazuje s.prunelm.5c296ad6.20130421-0054

Pak jsou i dalsi korpusy, ale ty nemaji csNmT1:
mono-cwc-discussions/csNm+form  65253322
mono-w2c/csNm+form      9026781

Alesovy korpusy:
s.lm.4a4cb068.20130313-1343 (DONE)    mono-cwc-articles	pouzito
s.lm.bd0ac0bd.20130313-1413 (DONE)    mono-cnk-other   	prekonano 7gr
s.lm.6eb3e145.20130312-1627 (DONE)    europarl         	nepouzivam
s.lm.9f2327ed.20130313-1351 (DONE)    mono-cwc-blogs	pouzito

Rucni oprava spadleho velkeho LM se dela takto:
ssh STROJ
tempdir=/mnt/h/tmp/exp.lm.8RHf13
outdir=/net/tmp/bojar/wmt13-bojar/playground/s.lm.9921e4a8.20130417-2004
cd $tempdir
qsubmit -queue='*@STROJ*' -mem=30g "SRILMDIR1=$(cat /a/merkur3/TMP/bojar/wmt13-bojar/playground/wmt-corpora/s.srilm.2a0e3a00.20130211-1907/srilm.path)/bin/; SRILMDIR2=$(cat /a/merkur3/TMP/bojar/wmt13-bojar/playground/wmt-corpora/s.srilm.2a0e3a00.20130211-1907/srilm.path)/bin/i686/; export PATH=\$SRILMDIR1:\$SRILMDIR2:\$PATH; make-big-lm -read $tempdir/*.ngrams.gz -name $tempdir/biglm -order 10 -interpolate -kndiscount -lm $outdir/corpus.lm"

Zkusim pouzit hodne LM:
Odvozuju z: f4b02947.20130417-0028 (16.46)
  cwc-oba 6gr: s.evaluator.2dcf7793.20130418-0857 ... uz potrebuje 50g :-(

Odvozuju z: s.evaluator.aecb8ce9.20130417-0001 (0.1645, maxpl 7)
  s.prunelm.1b34d02b.20130417-2021 7gr-cwc-art (a mononews a tagy z CzEngu)
  -> s.evaluator.2e69e025.20130418-1842 16.63±0.54


2013-04-17

Predikce prekladu 'to':

takto jsem to vyrobil:
ziplines --item-d='\t' <(./corpman -dump czeng10+europarl/csNmT1+form+lemma+tag) <(./corpman -dump czeng10+europarl/enNmT1+stc) <(./corpman -dump czeng10+europarl/gdfa-enNmT1-lemma-csNmT1-lemma+ali | ../scripts/reverse_alignment.pl ) | tools/move_info_along_ali.pl | gzip > czeng10+europarl-csNmT1+form+lemma+tag-back-in-enNmT1-for-classes-of-to.gz

... to ted pro prunik budu mit ulozeno jako korpus:
     czeng10+europarl/enNmT1+csINTstc+csINTlemma+csINTtag
     (s.corpus.9e2e04e9.20130419-1238)

log viz toklas.o7323637


Takhle se pak muzu divat soucasne na vstup a ocekavany vystup klasifikatoru:
./factor_combinator.pl <(./corpman czeng10+europarl/enNmT1+stc -dump) -1 0 <(zcat czeng10+europarl-csNmT1+form+lemma+tag-back-in-enNmT1-for-classes-of-to.gz | tools/construct_class_of_en_to_from_czech_flt.pl) -1 0 | less


Takhle jsem si udelal vzorek na 500k vetach:
(pozor, je tam zkraceny korpus, je to jen CzEng:)
./factor_combinator.pl <(./corpman czeng10/enNmT1+stc -dump) -1 0 <(./corpman czeng10/enNmT1+form+lemma+tag -dump) -1 1  <(./corpman czeng10/enNmT1+form+lemma+tag -dump) -1 2 <(zcat czeng10+europarl-csNmT1+form+lemma+tag-back-in-enNmT1-for-classes-of-to.gz | tools/construct_class_of_en_to_from_czech_flt.pl) -1 0 | head -n 500000 | gzip > toclass-minicorpus-500k.gz

... podklad pro tools/construct_class_of_en_to_from_czech_flt.pl
    tedy dostanu pozadavkem na korpus:
    czeng10+europarl/enNmT1+csINTstc+csINTlemma+csINTtag
    ... a vystup ukladam do faktoru toclass01

Takhle jsem to provedl v kroku korpus:
OUTLINECOUNT=15478910 OUTCORP=czeng10+europarl OUTLANG=enNmT1 OUTFACTS=toclass01 RUN_COMMAND="../tools/construct_class_of_en_to_from_czech_flt.pl" STEPNAME=s.corpus.9e2e04e9.20130419-1238 FILENAME=corpus.txt.gz eman init corpus --start


A dalsi krok je trenovani:

Podklad pro trenovani je tento korpus
    czeng10+europarl/enNmT1+form+lemma+tag+toclass
    (forma se ve skutecnosti nepouziva, davam ji tam jen protoze se rychleji
    takovy korpus sestavoval -- nemusel jsem ho vyrabet -- ale kdybych musel,
    tak je lepsi rovnou formu neuvadet a upravit i skript
    tools/predict_en_to_class.pl)

Takhle jsem ho prevedl na featury:
zcat toclass-minicorpus-500k.gz  | tools/predict_en_to_class.pl clipmodel --train --temp=toclass-minicorpus-500k

A takhle se to trenuje a vyhodnocuje cross-validaci:
cd ../src/maxent
./src/opt/maxent ../../playground/toclass-minicorpus-500k.events -n10 -mclipmodel

Kdyz je to 50k vet, tak je uspesnost kolem 34.548%
Kdyz je to 500k vet, tak spis: 42.1458% (okenko +-3)
500k vet, okenko +-4: stejne, ne-li horsi: 41.7374%

Zjednodusena predikce: (jen -, aby, az, Vf, V, R, N, ...)
50k vet: 48.75%
500k vet: 53.2496%

druhe zjednoduseni: - aby az, Vf, Vs, V, ale uz ne treba A
500k:	53.5338%
500k-GIS: 54.7392% (predikce na trenovaich datech dava 75.2894%)

500k-GIS, jen lexikalni a nikoli pozicni featury: 52.1313%

500k-GIS -alignment zalozen na pruniku: 72.7933%


2013-04-18

Sestavim si veliky tuning set:

OUTCORP=bigref11a,b,c,d

konkatenaci techto casti:

en          	a           	b              	c              	d
newstest2011	newstest2011	wmt11-extraref1	wmt11-extraref2	wmt11-extraref3
wmt11-hpe1  	wmt11-hpe1  	wmt11-hpe2     	wmt11-hpe1     	wmt11-hpe2
newstest2009	newstest2009	newstest2009   	newstest2009   	newstest2009
newstest2008	newstest2008	newstest2008   	newstest2008   	newstest2008
newstest2007	newstest2007	newstest2007   	newstest2007   	newstest2007

OUTCORP=bigref11a OUTLANG=en_txt OUTFACTS=untoken OUTLINECOUNT=11583

OUTCORP=bigref11a OUTLANG=en_txt OUTFACTS=untoken OUTLINECOUNT=11583 TAKE_FROM_COMMAND="../corpman newstest2011+wmt11-hpe1+newstest2009+newstest2008+newstest2007/en_txt+untoken --dump" eman init corpus --start
OUTCORP=bigref11a OUTLANG=cs_txt OUTFACTS=untoken OUTLINECOUNT=11583 TAKE_FROM_COMMAND="../corpman newstest2011+wmt11-hpe1+newstest2009+newstest2008+newstest2007/cs_txt+untoken --dump" eman init corpus --start

OUTCORP=bigref11b OUTLANG=cs_txt OUTFACTS=untoken OUTLINECOUNT=11583 TAKE_FROM_COMMAND="../corpman wmt11-extraref1+wmt11-hpe2+newstest2009+newstest2008+newstest2007/cs_txt+untoken --dump" eman init corpus --start
OUTCORP=bigref11c OUTLANG=cs_txt OUTFACTS=untoken OUTLINECOUNT=11583 TAKE_FROM_COMMAND="../corpman wmt11-extraref2+wmt11-hpe1+newstest2009+newstest2008+newstest2007/cs_txt+untoken --dump" eman init corpus --start
OUTCORP=bigref11d OUTLANG=cs_txt OUTFACTS=untoken OUTLINECOUNT=11583 TAKE_FROM_COMMAND="../corpman wmt11-extraref3+wmt11-hpe2+newstest2009+newstest2008+newstest2007/cs_txt+untoken --dump" eman init corpus --start

Na bigrefu zkusim vyladit nejvetsi model:
base	s.evaluator.54f6a944.20130416-0056	0.1647
MERT	s.evaluator.dd320acc.20130419-0724	0.1631
MIRA	s.evaluator.3385cc6b.20130419-0948

Novy nejvetsi:
base	s.evaluator.2e69e025.20130418-1842	0.1663
MERT	s.evaluator.b5e0b0c7.20130419-2342

a ten MERT zkusim take na bigrefu:
  s.evaluator.b5e0b0c7.20130419-2342


2013-04-19

V ramci odstraneni hloupych chyb zkusim mert na velkem devsetu t0a1-0a1 *s* reorderingem.
Rucne model sestavuju z s.evaluator.b225c1b0.20130328-1441 a s.evaluator.dd320acc.20130419-0724
=> s.evaluator.09235bda.20130419-1038
   ... nejak jsem blbec pouzil spatny tm
   oprava: s.evaluator.5bcf4626.20130420-2205
   oprava: s.evaluator.e270ce19.20130421-0041


2013-04-19

Zkoumam, ktera slova jsou casto zarovnana na NULL, napadlo mne to, kdyz jsem se dival na preklady 'to':

NULL                                            to|TO   0.1188230
na|RR--4----------                              to|TO   0.0917442
k|RR--3----------                               to|TO   0.0659280
aby|J,-------------                             to|TO   0.0478492
se|P7-X4----------                              to|TO   0.0407166
do|RR--2----------                              to|TO   0.0358436
pro|RR--4----------                             to|TO   0.0274111
s|RR--7----------                               to|TO   0.0223520
podle|RR--2----------                           to|TO   0.0191064
ke|RV--3----------                              to|TO   0.0131588
na|RR--6----------                              to|TO   0.0115121
že|J,-------------                              to|TO   0.0113417
v|RR--6----------                               to|TO   0.0088140
o|RR--4----------                               to|TO   0.0079569
o|RR--6----------                               to|TO   0.0077580
si|P7-X3----------                              to|TO   0.0061279
chcete|VB-P---2P-AA---                          to|TO   0.0056790
musí|VB-S---3P-AA---                            to|TO   0.0053501
a|J^-------------                               to|TO   0.0052474
za|RR--4----------                              to|TO   0.0050220



2013-04-19

velikost ttablu:
/net/tmp/bojar/wmt13-bojar/playground/s.tm.82dadcf1.20130312-2202/model/phrase-table.0,1-0,1.gz

55227432794	rozbalena
8215065557	gzip (standard)
6880453441	gzip jednotlivych sloupcu

zabaleno po sloucich:
1074925103	column 1
2153882164	column 2
3263437733	column 3
579409	column 4
387629032	column 5
