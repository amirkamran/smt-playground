Jednojazycna data
-----------------

* Google Ngrams
  /net/data/google-czech-ngrams-2009/
  Navod, jak z nich vyrobit LM:
    http://www-speech.sri.com/projects/srilm/manpages/srilm-faq.7.html

* CNK
  /mnt/ATLAS/data/CNK-SYN
  ...je treba zjistit, jak se lisi od toho, co jsem parsoval zde:
     /net/data/tectomt-SYN-WEB

* Webovy korpus 2011 (CWC2011, Johanka)
  /net/cluster/TMP/pecina/CWC2011
  nebo taky /mnt/ATLAS/data/CWC2011

                            sents   toks
    articles_shuffled       38 M    628 M
    blogs_shuffled          98 M    1249 M
    discussions_shuffled    82 M    1407 M
    TOTAL                   218 M   3284 M

  Konverzni skript:
    /home/bojar/diplomka/bin/vertical2factors --input-sent-regex='^<s>'

* WMT Mono News 20*
  /a/merkur3/TMP/tamchyna/wmt13/data
  Mixture-LM podle let? Ano, ale michat podle neceho aktualnejsiho nez wmt08.

* monitoring-tisk 2012
  /ha/seznamdata/texty_z_monitoringu
  nebo taky /mnt/ATLAS/data/MonitoringTisku1998-2012 (tam se to jeste vali)

* CzEng 1.0
  /net/data/czeng10-public-release
  Mixture-LM podle domen? Ano, urcite.
  Pozor, to michani bychom taky meli delat nejak lepe, mixovat na wmt08 se v
  roce 13 uz nemusi uplne hodit...

* Seznam.cz 2008
  /mnt/ATLAS/data/Seznam2008 (tam se to jeste vali)
  aktualne to lezi i zde:
  /ha/seznamdata/seznam_texty_z_webu/ftp/b-[0-9]*.gz
  ...pridaval bych to az jako posledni zdroj.
  ...zacal jsem pro ten ucel psat dva skripty, ale nepamatuji si, jak daleko jsem dosel:
    ufal-smt-playground/playground/augmented_corpora/prep-wmt10/
      select_czech_sents_from_seznamdata.pl
      refine_and_truecase_czech_sents.pl

* Martin Majlis -- webovy korpus
  ufal/~majlis/w2c

Dalsi?

Paralelni data
--------------

* CzEng 1.0
  /net/data/czeng10-public-release

* Prekladove pameti Evropskeho centra pro prevenci chorob
    http://langtech.jrc.ec.europa.eu/ECDC-TM.html

*? Neco stahnout pomoci Panacea Tools?

Dalsi?



Cisteni, normalizace
--------------------

Potrebujeme jednotnou pipeline. Kterou pouzit?

- TrTok na segmentaci na vety, nikoli na tokenizaci
- playground/treex_scenarios/{cs,en}Nm.scen
  ... Nm znaci normalizovane a na m-rovine.
  ... normalizace jsou prave bloky jako W2W::NormalizeCzechSentence
      jeste bychom normalizaci mohli zkontrolovat a vylepsit

* Kontrola jednotnosti

- doporucuju 64bit binarku suspicious_tokenization (pozor, nacita bigramy do pameti!):

  cat corpus1 corpus2 corpus3 | ~/tools/src/obotools/suspicious_tokenization \
  | numsort n3

  Vypise to neco jako:

se na           sena            24      1
na to           nato            18      2
do konce        dokonce         9       30
že na           žena            8       9
za to           zato            6       3
jako by         jakoby          5       1
z ní            zní             5       5
před tím        předtím         4       10

Zde je evidentni, ze jsou to vsechno plane poplachy. Ale mohou tam byt veci
jako "us." vs. "us .". Cisla za temi dvema variantami jsou pocty vyskytu jedne
a druhe varianty.


2013-03-05

- experimentuju s ruznym poctem referencnich vet
  - vetsi devset nepomohl
  - vic referenci by melo pomoct
  - posteditovane reference?
    - dve varianty za sebou?
    - dve varianty jako alternativni reference?
  - spojeni obycejnych + posteditovanych?
  ... vse celkem bez hmatatelnych rozdilu

  ... takto se to vyhodnocuje:
./qj devset-hpe-7sys 10.63.0.53 10.62.0.53 10.61.0.54 10.60.0.54 10.47.0.53 10.53.0.51 10.42.0.52 | sed 's/\*\*/2/;s/\*/1/' | tabrecalc 'EVAL COL1*COL2 LAVE\tCOL3' | grp --keys=2 --items=SUM1 | numsort 2

dosavadni vysledky:
sys1, 10.63.0.53        7
sys3, 10.61.0.54        10
sys5, 10.47.0.53        11
sys6, 10.53.0.51        11
sys2, 10.62.0.53        12
sys4, 10.60.0.54        12
sys7, 10.42.0.52        14

nejlepsi 10.42.0.52 je prekvapive DEVwmt11-hpe1:wmt11-hpe2, druhy je DEVnewstest2011:wmt11-extraref1:wmt11-extraref2:wmt11-extraref3 a DEVnewstest2011:wmt11-extraref1

- vyrobim korpus jen z titulku z monitoringu tisku
  pak vysekame titulky ze vsech devtestu a vyladime na tom vlastni preklad
    (bud obecneho mosese nebo navic s tim titulkovym lm)
  a pak prelozime testset dvakrat: normalne a titulkove
  ...a prislusne vety vezmeme z prislusnych casti


Odlisna spojeni:
- have to be careful not to get under an avalanche
potrebuje frazi "not to get" = "abyste se nedostali/la/lo"
...chtelo by to overit, jak se na takovehle pripady diva alignment...

- "obviously, " to naopak pekne preklada jako "je zrejme, ze"

- "believed in his motto saying that" = "rikajici", "ktere rika"
  (prvni volba je atypicky slovni tvar, druha volba zas generuje slovo navic a tim je mozna znevyhodnena"

Chyby:
- pojmenovane entity!
SRC     `` Charles University has been greatly involved in the festival . ''
REF     „ univerzita Karlova má na festivalu velký podíl . “
        „ Charles univerzity se významně podílely na festivalu “ .
        „ Charles univerzity se významně podílely na festivalu . “
        „ aktivit se významně podílely na festivalu “ . 
        „ aktivit se významně podílely na festivalu . “

